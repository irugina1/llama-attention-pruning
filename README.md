# llama-attention-pruning

Llama2 inference with data-informed sparse attention on modal labs A100 using deepspeed.
